{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e257e919",
   "metadata": {},
   "source": [
    "### Routine per il fine tuning del modello "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    GridSearchCV, \n",
    "    RandomizedSearchCV,\n",
    "    \n",
    "    StratifiedKFold\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a0cee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggi i dati e le etichette dai file Parquet nella cartella preprocessed/binary/data_w_features\n",
    "features_df = pd.read_parquet('processed_data/binary_classification/data_w_features/combined_features.parquet')\n",
    "labels_df = pd.read_parquet('processed_data/binary_classification/data_w_features/labels_binary_stats_features_only.parquet')\n",
    "\n",
    "# Campiona 10000 righe con distribuzione bilanciata tra le classi di labels_df\n",
    "n_samples_per_class = 500000  # 10000/2 per due classi\n",
    "sampled_indices = (\n",
    "    labels_df.groupby(labels_df.iloc[:, 0])\n",
    "    .apply(lambda x: x.sample(n=n_samples_per_class, random_state=42))\n",
    "    .index.get_level_values(1)\n",
    ")\n",
    "features_df = features_df.loc[sampled_indices].reset_index(drop=True)\n",
    "labels_df = labels_df.loc[sampled_indices].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ade8861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 1000000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_df), len(labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3bd3bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 500000, 1: 500000})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(labels_df.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6f83b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestTuner:\n",
    "    def __init__(self, features_df, labels_df, target_column='O', test_size=0.2, random_state=42):\n",
    "        \"\"\"\n",
    "        Inizializza il tuner per Random Forest\n",
    "        \n",
    "        Args:\n",
    "            features_df: DataFrame con le features\n",
    "            labels_df: DataFrame con le labels\n",
    "            target_column: nome della colonna target\n",
    "            test_size: proporzione del test set\n",
    "            random_state: seed per riproducibilità\n",
    "        \"\"\"\n",
    "        self.features_df = features_df\n",
    "        self.labels_df = labels_df\n",
    "        self.target_column = target_column\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Inizializza attributi\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "        self.cv_results = None\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepara i dati per il training\"\"\"\n",
    "        print(\"Preparazione dei dati...\")\n",
    "        \n",
    "        # Estrai features e target\n",
    "        X = self.features_df.copy()\n",
    "        y = self.labels_df[self.target_column].copy()\n",
    "        \n",
    "        # Gestisci valori mancanti\n",
    "        X = X.fillna(X.median() if X.select_dtypes(include=[np.number]).shape[1] > 0 else X.mode().iloc[0])\n",
    "        \n",
    "        # Encoding delle variabili categoriche se presenti\n",
    "        categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "        if len(categorical_columns) > 0:\n",
    "            print(f\"Encoding di {len(categorical_columns)} variabili categoriche\")\n",
    "            for col in categorical_columns:\n",
    "                le = LabelEncoder()\n",
    "                X[col] = le.fit_transform(X[col].astype(str))\n",
    "        \n",
    "        # Split train/test\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=self.test_size, random_state=self.random_state, \n",
    "            stratify=y if len(np.unique(y)) > 1 else None\n",
    "        )\n",
    "        \n",
    "        print(f\"Dimensioni training set: {self.X_train.shape}\")\n",
    "        print(f\"Dimensioni test set: {self.X_test.shape}\")\n",
    "        print(\"Distribuzione classi nel training set:\")\n",
    "        print(self.y_train.value_counts().sort_index())\n",
    "        \n",
    "    def define_param_grids(self):\n",
    "        \"\"\"Definisce le griglie di parametri per la ricerca\"\"\"\n",
    "        \n",
    "        # Griglia completa per GridSearch (più lenta ma esaustiva)\n",
    "        self.grid_params = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['sqrt', 'log2', None],\n",
    "            'bootstrap': [True, False]\n",
    "        }\n",
    "        \n",
    "        # Griglia per RandomizedSearch (più veloce)\n",
    "        self.random_params = {\n",
    "            'n_estimators': stats.randint(50, 500),\n",
    "            'max_depth': [None] + list(range(10, 50, 5)),\n",
    "            'min_samples_split': stats.randint(2, 20),\n",
    "            'min_samples_leaf': stats.randint(1, 10),\n",
    "            'max_features': ['sqrt', 'log2', None, 0.5, 0.7, 0.9],\n",
    "            'bootstrap': [True, False],\n",
    "            'max_samples': [None, 0.7, 0.8, 0.9] if True else [None]  # Solo se bootstrap=True\n",
    "        }\n",
    "        \n",
    "    def grid_search_tuning(self, cv_folds=5, scoring='accuracy', n_jobs=-1):\n",
    "        \"\"\"\n",
    "        Esegue Grid Search per trovare i parametri ottimali\n",
    "        \n",
    "        Args:\n",
    "            cv_folds: numero di fold per cross-validation\n",
    "            scoring: metrica di scoring\n",
    "            n_jobs: numero di processi paralleli\n",
    "        \"\"\"\n",
    "        print(\"\\n=== GRID SEARCH TUNING ===\")\n",
    "        print(\"Avvio Grid Search (può richiedere diversi minuti)...\")\n",
    "        \n",
    "        # Definisci il modello base\n",
    "        rf = RandomForestClassifier(random_state=self.random_state)\n",
    "        \n",
    "        # Setup cross-validation\n",
    "        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        # Grid Search\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=rf,\n",
    "            param_grid=self.grid_params,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=n_jobs,\n",
    "            verbose=1,\n",
    "            return_train_score=True\n",
    "        )\n",
    "        \n",
    "        # Fit del modello\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # Salva i risultati\n",
    "        self.best_model = grid_search.best_estimator_\n",
    "        self.best_params = grid_search.best_params_\n",
    "        self.cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "        \n",
    "        print(\"\\nMigliori parametri trovati:\")\n",
    "        for param, value in self.best_params.items():\n",
    "            print(f\"  {param}: {value}\")\n",
    "        print(f\"\\nMiglior score CV: {grid_search.best_score_:.4f}\")\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def randomized_search_tuning(self, n_iter=100, cv_folds=5, scoring='accuracy', n_jobs=-1):\n",
    "        \"\"\"\n",
    "        Esegue Randomized Search per trovare i parametri ottimali\n",
    "        \n",
    "        Args:\n",
    "            n_iter: numero di combinazioni di parametri da testare\n",
    "            cv_folds: numero di fold per cross-validation\n",
    "            scoring: metrica di scoring\n",
    "            n_jobs: numero di processi paralleli\n",
    "        \"\"\"\n",
    "        print(\"\\n=== RANDOMIZED SEARCH TUNING ===\")\n",
    "        print(f\"Avvio Randomized Search con {n_iter} iterazioni...\")\n",
    "        \n",
    "        # Definisci il modello base\n",
    "        rf = RandomForestClassifier(random_state=self.random_state)\n",
    "        \n",
    "        # Setup cross-validation\n",
    "        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        # Randomized Search\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=rf,\n",
    "            param_distributions=self.random_params,\n",
    "            n_iter=n_iter,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=n_jobs,\n",
    "            verbose=1,\n",
    "            random_state=self.random_state,\n",
    "            return_train_score=True\n",
    "        )\n",
    "        \n",
    "        # Fit del modello\n",
    "        random_search.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # Salva i risultati\n",
    "        self.best_model = random_search.best_estimator_\n",
    "        self.best_params = random_search.best_params_\n",
    "        self.cv_results = pd.DataFrame(random_search.cv_results_)\n",
    "        \n",
    "        print(\"\\nMigliori parametri trovati:\")\n",
    "        for param, value in self.best_params.items():\n",
    "            print(f\"  {param}: {value}\")\n",
    "        print(f\"\\nMiglior score CV: {random_search.best_score_:.4f}\")\n",
    "        \n",
    "        return random_search\n",
    "    \n",
    "    def evaluate_model(self, plot_results=True):\n",
    "        \"\"\"Valuta il modello ottimizzato\"\"\"\n",
    "        if self.best_model is None:\n",
    "            print(\"Errore: Nessun modello è stato addestrato ancora!\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n=== VALUTAZIONE DEL MODELLO ===\")\n",
    "        \n",
    "        # Predizioni\n",
    "        y_pred = self.best_model.predict(self.X_test)\n",
    "        y_pred_proba = self.best_model.predict_proba(self.X_test)\n",
    "        \n",
    "        # Metriche di base\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(self.y_test, y_pred, average='weighted')\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "        \n",
    "        # ROC AUC per problemi binari o multiclasse\n",
    "        try:\n",
    "            if len(np.unique(self.y_test)) == 2:\n",
    "                auc = roc_auc_score(self.y_test, y_pred_proba[:, 1])\n",
    "                print(f\"ROC AUC: {auc:.4f}\")\n",
    "            else:\n",
    "                auc = roc_auc_score(self.y_test, y_pred_proba, multi_class='ovr')\n",
    "                print(f\"ROC AUC (multiclass): {auc:.4f}\")\n",
    "        except ValueError:\n",
    "            print(\"ROC AUC non calcolabile\")\n",
    "        \n",
    "        # Classification report dettagliato\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "        \n",
    "        # Feature importance\n",
    "        if hasattr(self.best_model, 'feature_importances_'):\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': self.X_train.columns,\n",
    "                'importance': self.best_model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(\"\\nTop 10 Feature più importanti:\")\n",
    "            print(feature_importance.head(10))\n",
    "        \n",
    "        # Plot dei risultati\n",
    "        if plot_results:\n",
    "            self.plot_results(y_pred, feature_importance if 'feature_importance' in locals() else None)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_pred_proba\n",
    "        }\n",
    "    \n",
    "    def plot_results(self, y_pred, feature_importance=None):\n",
    "        \"\"\"Crea visualizzazioni dei risultati\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # 1. Confusion Matrix\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0])\n",
    "        axes[0,0].set_title('Confusion Matrix')\n",
    "        axes[0,0].set_xlabel('Predicted')\n",
    "        axes[0,0].set_ylabel('Actual')\n",
    "        \n",
    "        # 2. Feature Importance\n",
    "        if feature_importance is not None:\n",
    "            top_features = feature_importance.head(15)\n",
    "            axes[0,1].barh(range(len(top_features)), top_features['importance'])\n",
    "            axes[0,1].set_yticks(range(len(top_features)))\n",
    "            axes[0,1].set_yticklabels(top_features['feature'])\n",
    "            axes[0,1].set_title('Top 15 Feature Importance')\n",
    "            axes[0,1].set_xlabel('Importance')\n",
    "        \n",
    "        # 3. Cross-validation scores\n",
    "        if self.cv_results is not None:\n",
    "            cv_scores = self.cv_results['mean_test_score']\n",
    "            axes[1,0].hist(cv_scores, bins=30, alpha=0.7, color='skyblue')\n",
    "            axes[1,0].axvline(cv_scores.max(), color='red', linestyle='--', \n",
    "                             label=f'Best: {cv_scores.max():.4f}')\n",
    "            axes[1,0].set_title('Distribuzione CV Scores')\n",
    "            axes[1,0].set_xlabel('CV Score')\n",
    "            axes[1,0].set_ylabel('Frequency')\n",
    "            axes[1,0].legend()\n",
    "        \n",
    "        # 4. Distribuzione classi predette vs reali\n",
    "        comparison_df = pd.DataFrame({\n",
    "            'Actual': self.y_test,\n",
    "            'Predicted': y_pred\n",
    "        })\n",
    "        \n",
    "        actual_counts = comparison_df['Actual'].value_counts().sort_index()\n",
    "        pred_counts = comparison_df['Predicted'].value_counts().sort_index()\n",
    "        \n",
    "        x_pos = np.arange(len(actual_counts))\n",
    "        width = 0.35\n",
    "        \n",
    "        axes[1,1].bar(x_pos - width/2, actual_counts.values, width, \n",
    "                     label='Actual', alpha=0.8)\n",
    "        axes[1,1].bar(x_pos + width/2, pred_counts.values, width, \n",
    "                     label='Predicted', alpha=0.8)\n",
    "        axes[1,1].set_title('Distribuzione Classi: Actual vs Predicted')\n",
    "        axes[1,1].set_xlabel('Classe')\n",
    "        axes[1,1].set_ylabel('Count')\n",
    "        axes[1,1].set_xticks(x_pos)\n",
    "        axes[1,1].set_xticklabels(actual_counts.index)\n",
    "        axes[1,1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def run_complete_pipeline(self, search_type='randomized', **kwargs):\n",
    "        \"\"\"\n",
    "        Esegue la pipeline completa di tuning\n",
    "        \n",
    "        Args:\n",
    "            search_type: 'grid' o 'randomized'\n",
    "            **kwargs: parametri aggiuntivi per la ricerca\n",
    "        \"\"\"\n",
    "        print(\"🚀 AVVIO PIPELINE COMPLETA DI TUNING\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 1. Preparazione dati\n",
    "        self.prepare_data()\n",
    "        \n",
    "        # 2. Definizione parametri\n",
    "        self.define_param_grids()\n",
    "        \n",
    "        # 3. Ricerca parametri\n",
    "        if search_type.lower() == 'grid':\n",
    "            search_results = self.grid_search_tuning(**kwargs)\n",
    "        else:\n",
    "            search_results = self.randomized_search_tuning(**kwargs)\n",
    "        \n",
    "        # 4. Valutazione finale\n",
    "        evaluation_results = self.evaluate_model()\n",
    "        \n",
    "        print(\"\\n🎉 PIPELINE COMPLETATA!\")\n",
    "        return search_results, evaluation_results\n",
    "\n",
    "# ================================\n",
    "# ESEMPIO DI UTILIZZO\n",
    "# ================================\n",
    "\n",
    "def main_example():\n",
    "    \"\"\"Esempio di utilizzo della pipeline\"\"\"\n",
    "    \n",
    "    # Assumendo che hai già features_df e labels_df\n",
    "    # features_df = your_features_dataframe\n",
    "    # labels_df = your_labels_dataframe\n",
    "    \n",
    "    # Inizializza il tuner\n",
    "    tuner = RandomForestTuner(\n",
    "        features_df=features_df, \n",
    "        labels_df=labels_df, \n",
    "        target_column='0',\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Opzione 1: Pipeline completa con Randomized Search (raccomandato)\n",
    "    search_results, eval_results = tuner.run_complete_pipeline(\n",
    "        search_type='randomized',\n",
    "        n_iter=50,  # Riduci per test più veloci\n",
    "        cv_folds=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Opzione 2: Pipeline completa con Grid Search (più lenta)\n",
    "    # search_results, eval_results = tuner.run_complete_pipeline(\n",
    "    #     search_type='grid',\n",
    "    #     cv_folds=3,  # Riduci per velocizzare\n",
    "    #     scoring='f1_weighted',\n",
    "    #     n_jobs=-1\n",
    "    # )\n",
    "    \n",
    "    # Accesso ai risultati\n",
    "    print(f\"\\nMiglior modello: {tuner.best_model}\")\n",
    "    print(f\"Migliori parametri: {tuner.best_params}\")\n",
    "    \n",
    "    return tuner\n",
    "\n",
    "# Per eseguire la pipeline, decommentare:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ea8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 AVVIO PIPELINE COMPLETA DI TUNING\n",
      "==================================================\n",
      "Preparazione dei dati...\n",
      "Dimensioni training set: (800000, 134)\n",
      "Dimensioni test set: (200000, 134)\n",
      "Distribuzione classi nel training set:\n",
      "0\n",
      "0    400000\n",
      "1    400000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== RANDOMIZED SEARCH TUNING ===\n",
      "Avvio Randomized Search con 50 iterazioni...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "tuner = main_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2da22b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "great_clf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
