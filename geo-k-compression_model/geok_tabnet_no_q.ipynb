{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38aafd7c",
   "metadata": {},
   "source": [
    "### Routine to train and tabnet model\n",
    "\n",
    "##### TODOs:\n",
    "- Set MlFlow tracking URI\n",
    "- Start mlflow server: mlflow server --host 127.0.0.1 --port 8080 (LOCAL)\n",
    "- Change folders if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd28585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Optional, Union, List, Dict\n",
    "from dataclasses import dataclass, field\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, kurtosis, entropy, randint, uniform, loguniform\n",
    "from scipy.fft import fft\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.calibration import calibration_curve\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import pyarrow as pa\n",
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc,\n",
    "    precision_recall_curve, average_precision_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Deep learning and specialized ML libraries\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d740f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23e22bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MlFlow tracking URI\n",
    "mlflow.set_tracking_uri(\"http://localhost:8080\") # Check your MLflow server URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca997b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDMFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    @staticmethod\n",
    "    def gini(array):\n",
    "            \"\"\"Gini coefficient calculation\"\"\"\n",
    "            array = np.sort(array)\n",
    "            index = np.arange(1, array.shape[0] + 1)\n",
    "            return (np.sum((2 * index - array.shape[0] - 1) * array)) / (array.shape[0] * np.sum(array))  \n",
    "      \n",
    "    def extract_ddm_features(self, fit_data: np.ndarray) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extract features from DDM data.\n",
    "        \"\"\"\n",
    "        features = []\n",
    "\n",
    "        for row in tqdm(fit_data, desc=\"Extracting DDM features\"):\n",
    "            f = {}\n",
    "            x = np.array(row, dtype=np.float64) + 1e-10  # evita log(0)\n",
    "\n",
    "            # 1. General statistics\n",
    "            f['mean'] = np.mean(x)\n",
    "            f['std'] = np.std(x)\n",
    "            f['min'] = np.min(x)\n",
    "            f['max'] = np.max(x)\n",
    "            f['median'] = np.median(x)\n",
    "            f['range'] = np.max(x) - np.min(x)\n",
    "            f['skew'] = skew(x)\n",
    "            f['kurtosis'] = kurtosis(x)\n",
    "            f['entropy'] = entropy(x)\n",
    "            f['gini'] = self.gini(x)\n",
    "\n",
    "            # 2. Positional \n",
    "            f['peak_index'] = np.argmax(x)\n",
    "            f['peak_value'] = np.max(x)\n",
    "            f['center_of_mass'] = np.sum(np.arange(len(x)) * x) / np.sum(x)\n",
    "            f['inertia'] = np.sum(((np.arange(len(x)) - f['center_of_mass'])**2) * x)\n",
    "\n",
    "            # 3. Segmentations in thirds\n",
    "            thirds = np.array_split(x, 3)\n",
    "            for i, part in enumerate(thirds):\n",
    "                f[f'sum_third_{i+1}'] = np.sum(part)\n",
    "                f[f'mean_third_{i+1}'] = np.mean(part)\n",
    "                f[f'max_third_{i+1}'] = np.max(part)\n",
    "\n",
    "            # 3.1 Segmentations in windows of 5\n",
    "            windows = np.array_split(x, 5)\n",
    "            for i, w in enumerate(windows):\n",
    "                f[f'mean_w{i+1}'] = np.mean(w)\n",
    "                f[f'std_w{i+1}'] = np.std(w)\n",
    "                f[f'max_w{i+1}'] = np.max(w)\n",
    "\n",
    "            # 4. Derivative statistics and differences\n",
    "            dx = np.diff(x)\n",
    "            f['mean_diff'] = np.mean(dx)\n",
    "            f['std_diff'] = np.std(dx)\n",
    "            f['max_diff'] = np.max(dx)\n",
    "            f['min_diff'] = np.min(dx)\n",
    "            f['n_positive_diff'] = np.sum(dx > 0)\n",
    "            f['n_negative_diff'] = np.sum(dx < 0)\n",
    "            f['n_zero_diff'] = np.sum(dx == 0)\n",
    "\n",
    "            # 5. Autocorrelations (lag 1-3)\n",
    "            for lag in range(1, 4):\n",
    "                ac = np.corrcoef(x[:-lag], x[lag:])[0, 1] if len(x) > lag else np.nan\n",
    "                f[f'autocorr_lag{lag}'] = ac\n",
    "\n",
    "            # 6. FFT \n",
    "            spectrum = np.abs(fft(x)) # type: ignore\n",
    "            half_spectrum = spectrum[:len(spectrum)//2]  \n",
    "            f['fft_peak_freq'] = np.argmax(half_spectrum)\n",
    "            f['fft_max'] = np.max(half_spectrum)\n",
    "            f['fft_median'] = np.median(half_spectrum)\n",
    "            f['fft_mean'] = np.mean(half_spectrum)\n",
    "\n",
    "\n",
    "            features.append(f)\n",
    "        return features # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_path = r\"E:\\data\\geo_k_compressed\\full_data_dict.json\"\n",
    "with open(json_path, \"r\") as f:\n",
    "    full_data_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84832b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_numpy(dizionario):\n",
    "    \"\"\"\n",
    "    Converte un dizionario con struttura specificata in array numpy\n",
    "    \n",
    "    Args:\n",
    "        dizionario: {\"nome_file\": {\"compressed_data\": [...], \"labels\": [...]}}\n",
    "    \n",
    "    Returns:\n",
    "        data_matrix: array numpy (n_features, n_samples)\n",
    "        labels_array: array numpy con le labels\n",
    "        file_names: lista con i nomi dei file per riferimento\n",
    "    \"\"\"\n",
    "    \n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for nome_file, contenuto in dizionario.items():\n",
    "        compressed_data = contenuto[\"compressed_data\"]\n",
    "        labels = contenuto[\"labels\"]\n",
    "        \n",
    "        # Verifica che il numero di labels corrisponda al numero di array\n",
    "        if len(labels) != len(compressed_data):\n",
    "            print(f\"Attenzione: {nome_file} ha {len(compressed_data)} array ma {len(labels)} labels\")\n",
    "        \n",
    "        # Aggiungi i dati\n",
    "        for i, array_data in enumerate(compressed_data):\n",
    "            all_data.append(array_data)\n",
    "            all_labels.append(labels[i] if i < len(labels) else None)\n",
    "            \n",
    "    \n",
    "    # Converti in array numpy\n",
    "    data_matrix = np.array(all_data).T  # Trasponi per avere (features, samples)\n",
    "    labels_array = np.array(all_labels)\n",
    "    \n",
    "    return data_matrix.T, labels_array,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data, full_labels = dict_to_numpy(full_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c57f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extractor = DDMFeatureExtractor()\n",
    "\n",
    "def extract_ddm_features_row(row):\n",
    "    return features_extractor.extract_ddm_features(np.array([row]))\n",
    "\n",
    "combined_features = Parallel(n_jobs=12, backend=\"loky\")(delayed(extract_ddm_features_row)(row) for row in tqdm(full_data, desc=\"Estrazione features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69947ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES=list(combined_features[0][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe3c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_features = [row[0] if isinstance(row, list) and len(row) > 0 else row for row in combined_features]\n",
    "\n",
    "\n",
    "combined_features = np.array([[row[key] for key in FEATURES] for row in flat_features])\n",
    "del flat_features\n",
    "combined_features.shape\n",
    "\n",
    "# Check for NaN and infinite values\n",
    "mask_finite = np.isfinite(combined_features).all(axis=1) & (np.abs(combined_features) < np.finfo(np.float64).max).all(axis=1)\n",
    "\n",
    "fit_data_with_features_clean = combined_features[mask_finite]\n",
    "labels_clean = full_labels[mask_finite]\n",
    "del combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data_with_features_df = pd.DataFrame(fit_data_with_features_clean, columns=FEATURES)\n",
    "labels_clean_df = pd.DataFrame(labels_clean, columns=['0'])\n",
    "del fit_data_with_features_clean\n",
    "fit_data_with_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a42f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fit_data_with_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882bbe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a stratified subset (e.g., 10% of the data)\n",
    "X_subset, _, y_subset, _ = train_test_split(\n",
    "    fit_data_with_features_df,\n",
    "    labels_clean_df,\n",
    "    test_size=0.1,\n",
    "    stratify=labels_clean_df,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Reset index for convenience\n",
    "X_subset = X_subset.reset_index(drop=True)\n",
    "y_subset = y_subset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45edcd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabNetBinaryClassifier:\n",
    "    \"\"\"\n",
    "    Class for training a TabNet binary classifier with GPU support\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_d=32, \n",
    "                 n_a=32, \n",
    "                 n_steps=5, \n",
    "                 gamma=1.3,\n",
    "                 n_independent=2,\n",
    "                 n_shared=2,\n",
    "                 lambda_sparse=1e-3,\n",
    "                 optimizer_fn=torch.optim.Adam,\n",
    "                 optimizer_params=dict(lr=1e-2),\n",
    "                 mask_type='entmax',\n",
    "                 scheduler_params=dict(step_size=50, gamma=0.9),\n",
    "                 scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                 epsilon=1e-15,\n",
    "                 device_name='auto'):\n",
    "        \"\"\"\n",
    "        Initialize the TabNet classifier\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_d : int\n",
    "            Dimension of learned representations\n",
    "        n_a : int \n",
    "            Dimension of attention\n",
    "        n_steps : int\n",
    "            Number of steps in feature selection\n",
    "        gamma : float\n",
    "            Coefficient for aggregated attention\n",
    "        lambda_sparse : float\n",
    "            Regularization coefficient for sparsity\n",
    "        device_name : str\n",
    "            'auto', 'cuda', 'cpu' or specific device ('cuda:0')\n",
    "        \"\"\"\n",
    "        \n",
    "        # Device configuration\n",
    "        self.device = self._setup_device(device_name)\n",
    "        print(f\"Device used: {self.device}\")\n",
    "        \n",
    "        self.tabnet_params = {\n",
    "            'n_d': n_d,\n",
    "            'n_a': n_a, \n",
    "            'n_steps': n_steps,\n",
    "            'gamma': gamma,\n",
    "            'n_independent': n_independent,\n",
    "            'n_shared': n_shared,\n",
    "            'lambda_sparse': lambda_sparse,\n",
    "            'optimizer_fn': optimizer_fn,\n",
    "            'optimizer_params': optimizer_params,\n",
    "            'mask_type': mask_type,\n",
    "            'scheduler_params': scheduler_params,\n",
    "            'scheduler_fn': scheduler_fn,\n",
    "            'epsilon': epsilon,\n",
    "            'device_name': self.device\n",
    "        }\n",
    "        \n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_names = None\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def _setup_device(self, device_name):\n",
    "        \"\"\"\n",
    "        Configure the computing device (CPU/GPU)\n",
    "        \"\"\"\n",
    "        if device_name == 'auto':\n",
    "            if torch.cuda.is_available():\n",
    "                device = 'cuda'\n",
    "                print(f\"GPU available: {torch.cuda.get_device_name()}\")\n",
    "                print(f\"GPU memory available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "            else:\n",
    "                device = 'cpu'\n",
    "                print(\"GPU not available, using CPU\")\n",
    "        else:\n",
    "            device = device_name\n",
    "            if device.startswith('cuda') and not torch.cuda.is_available():\n",
    "                print(\"WARNING: GPU requested but not available, using CPU\")\n",
    "                device = 'cpu'\n",
    "        \n",
    "        return device\n",
    "    \n",
    "    def get_gpu_memory_info(self):\n",
    "        \"\"\"\n",
    "        Returns GPU memory information\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available() and self.device.startswith('cuda'):\n",
    "            device_idx = 0 if self.device == 'cuda' else int(self.device.split(':')[1])\n",
    "            allocated = torch.cuda.memory_allocated(device_idx) / 1e9\n",
    "            reserved = torch.cuda.memory_reserved(device_idx) / 1e9\n",
    "            total = torch.cuda.get_device_properties(device_idx).total_memory / 1e9\n",
    "            \n",
    "            print(f\"GPU Memory:\")\n",
    "            print(f\"  - Allocated: {allocated:.2f} GB\")\n",
    "            print(f\"  - Reserved: {reserved:.2f} GB\") \n",
    "            print(f\"  - Total: {total:.2f} GB\")\n",
    "            print(f\"  - Free: {total - reserved:.2f} GB\")\n",
    "            \n",
    "            return {\n",
    "                'allocated': allocated,\n",
    "                'reserved': reserved,\n",
    "                'total': total,\n",
    "                'free': total - reserved\n",
    "            }\n",
    "        else:\n",
    "            print(\"GPU memory not available\")\n",
    "            return None\n",
    "    \n",
    "    def clear_gpu_memory(self):\n",
    "        \"\"\"\n",
    "        Clear GPU memory\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"GPU cache cleared\")\n",
    "    \n",
    "    def prepare_data(self, X, y, target_col='y', test_size=0.2, random_state=42, scale_features=True):\n",
    "        \"\"\"\n",
    "        Prepare data for training\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pandas.DataFrame\n",
    "            DataFrame with data\n",
    "        target_col : str\n",
    "            Name of target column\n",
    "        test_size : float\n",
    "            Proportion of test set\n",
    "        random_state : int\n",
    "            Seed for reproducibility\n",
    "        scale_features : bool\n",
    "            Whether to apply scaling to features\n",
    "        \"\"\"\n",
    "        \n",
    "        # Separate features and target\n",
    "        X = X\n",
    "        y = y\n",
    "        \n",
    "        # Save feature names\n",
    "        self.feature_names = X.columns.tolist()\n",
    "        \n",
    "        # Convert to float32 to optimize GPU memory\n",
    "        X = X.astype(np.float32)\n",
    "        \n",
    "        # Split X and y into train (64%), validation (16%), and test (20%) sets\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            test_size=0.2,\n",
    "            stratify=y,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp,\n",
    "            y_temp,\n",
    "            test_size=0.2,  # 0.2 * 0.8 = 0.16 of the original data\n",
    "            stratify=y_temp,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Reset indices for convenience\n",
    "        X_train = X_train.reset_index(drop=True)\n",
    "        X_val = X_val.reset_index(drop=True)\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "        y_train = y_train.reset_index(drop=True)\n",
    "        y_val = y_val.reset_index(drop=True)\n",
    "        y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "        # Numeric columns will be scaled by StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        \n",
    "\n",
    "        column_trans = ColumnTransformer(\n",
    "            [ ('scaler',scaler, FEATURES),\n",
    "            ], remainder='passthrough', n_jobs=-1)\n",
    "\n",
    "        train_X_transformed = column_trans.fit_transform(X_train, y_train)\n",
    "        val_X_transformed = column_trans.transform(X_val )\n",
    "        test_X_transformed = column_trans.transform(X_test)\n",
    "\n",
    "        self.X_train = train_X_transformed\n",
    "        self.X_val = val_X_transformed\n",
    "        self.X_test = test_X_transformed\n",
    "\n",
    "\n",
    "        \n",
    "        # Convert to float32 for GPU\n",
    "        self.X_train = X_train.values.astype(np.float32)\n",
    "        self.y_train = y_train.values.astype(np.int64)\n",
    "\n",
    "        self.X_test = X_test.values.astype(np.float32)\n",
    "        self.y_test = y_test.values.astype(np.int64)\n",
    "\n",
    "        self.X_val = X_val.values.astype(np.float32)\n",
    "        self.y_val = y_val.values.astype(np.int64)\n",
    "\n",
    "        print(f\"Data prepared:\")\n",
    "        print(f\"  - Training set: {self.X_train.shape}\")\n",
    "        print(f\"  - Test set: {self.X_test.shape}\")\n",
    "        print(f\"  - Validation set: {self.X_val.shape}\")\n",
    "\n",
    "        \n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "    \n",
    "    def train(self, \n",
    "              max_epochs=200, \n",
    "              patience=15, \n",
    "              batch_size=1024,\n",
    "              virtual_batch_size=128,\n",
    "              num_workers=0,\n",
    "              drop_last=False):\n",
    "        \"\"\"\n",
    "        Train the TabNet model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        max_epochs : int\n",
    "            Maximum number of epochs\n",
    "        patience : int\n",
    "            Patience for early stopping\n",
    "        batch_size : int\n",
    "            Batch size\n",
    "        virtual_batch_size : int\n",
    "            Virtual batch size\n",
    "        num_workers : int\n",
    "            Number of workers for DataLoader (0 for GPU)\n",
    "        \"\"\"\n",
    "        \n",
    "        if not hasattr(self, 'X_train'):\n",
    "            raise ValueError(\"You must first prepare data with prepare_data()\")\n",
    "        \n",
    "        # Adapt batch_size for GPU\n",
    "        if self.device.startswith('cuda'):\n",
    "            gpu_memory = self.get_gpu_memory_info()\n",
    "            if gpu_memory and gpu_memory['free'] < 2.0:  # Less than 2GB free\n",
    "                suggested_batch_size = min(batch_size, 512)\n",
    "                print(f\"Limited GPU memory, reducing batch_size to {suggested_batch_size}\")\n",
    "                batch_size = suggested_batch_size\n",
    "            \n",
    "            # Optimize num_workers for GPU\n",
    "            if num_workers == 0:\n",
    "                num_workers = min(4, torch.cuda.device_count() * 2)\n",
    "                \n",
    "        print(\"Training configuration:\")\n",
    "        print(f\"  - Device: {self.device}\")\n",
    "        print(f\"  - Batch size: {batch_size}\")\n",
    "        print(f\"  - Virtual batch size: {virtual_batch_size}\")\n",
    "        print(f\"  - Num workers: {num_workers}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = TabNetClassifier(**self.tabnet_params)\n",
    "        \n",
    "        # Check memory before training\n",
    "        if self.device.startswith('cuda'):\n",
    "            self.clear_gpu_memory()\n",
    "            print(\"GPU memory before training:\")\n",
    "            self.get_gpu_memory_info()\n",
    "        \n",
    "        # Training\n",
    "        print(\"\\nStarting TabNet training...\") \n",
    "        \n",
    "        try:\n",
    "            self.model.fit(\n",
    "                X_train=self.X_train,\n",
    "                y_train=self.y_train.reshape(-1),\n",
    "                eval_set=[(self.X_val, self.y_val.reshape(-1))],\n",
    "                eval_name=['test'],\n",
    "                eval_metric=['accuracy', 'auc'],\n",
    "                max_epochs=max_epochs,\n",
    "                patience=patience,\n",
    "                batch_size=batch_size,\n",
    "                virtual_batch_size=virtual_batch_size,\n",
    "                num_workers=num_workers,\n",
    "                drop_last=drop_last,\n",
    "            )\n",
    "            \n",
    "            self.is_fitted = True\n",
    "            print(\"Training completed!\")\n",
    "            \n",
    "            # Check memory after training\n",
    "            if self.device.startswith('cuda'):\n",
    "                print(\"\\nGPU memory after training:\")\n",
    "                self.get_gpu_memory_info()\n",
    "                \n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e).lower():\n",
    "                print(\"\\nERROR: Insufficient GPU memory!\")\n",
    "                self.clear_gpu_memory()\n",
    "            raise e\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, X=None):\n",
    "        \"\"\"\n",
    "        Make predictions\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model has not been trained yet!\")\n",
    "        \n",
    "        if X is None:\n",
    "            X = self.X_test\n",
    "            \n",
    "        # Convert to float32 for consistency\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values.astype(np.float32)\n",
    "        elif not isinstance(X, np.ndarray):\n",
    "            X = np.array(X, dtype=np.float32)\n",
    "        else:\n",
    "            X = X.astype(np.float32)\n",
    "            \n",
    "        predictions = self.model.predict(X)\n",
    "        return predictions\n",
    "    \n",
    "    def predict_proba(self, X=None):\n",
    "        \"\"\"\n",
    "        Return prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model has not been trained yet!\")\n",
    "        \n",
    "        if X is None:\n",
    "            X = self.X_test\n",
    "            \n",
    "        # Convert to float32 for consistency\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values.astype(np.float32)\n",
    "        elif not isinstance(X, np.ndarray):\n",
    "            X = np.array(X, dtype=np.float32)\n",
    "        else:\n",
    "            X = X.astype(np.float32)\n",
    "            \n",
    "        probabilities = self.model.predict_proba(X)\n",
    "        return probabilities\n",
    "    \n",
    "    def evaluate(self, X=None, y=None, plot_results=True):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model has not been trained yet!\")\n",
    "        \n",
    "        if X is None:\n",
    "            X = self.X_test\n",
    "            y = self.y_test\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = self.predict(X)\n",
    "        y_pred_proba = self.predict_proba(X)\n",
    "        \n",
    "        # Metrics\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        auc_score = roc_auc_score(y, y_pred_proba[:, 1])\n",
    "        \n",
    "        print(f\"\\n=== EVALUATION RESULTS ===\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"AUC Score: {auc_score:.4f}\")\n",
    "        print(f\"\\nClassification Report:\")\n",
    "        print(classification_report(y, y_pred))\n",
    "        \n",
    "        if plot_results:\n",
    "            self.plot_results(y, y_pred, y_pred_proba[:, 1])\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'auc_score': auc_score,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_pred_proba\n",
    "        }\n",
    "    \n",
    "    def plot_results(self, y_true, y_pred, y_pred_proba):\n",
    "        \"\"\"\n",
    "        Visualize results\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "        axes[0].set_title('Confusion Matrix')\n",
    "        axes[0].set_xlabel('Predicted')\n",
    "        axes[0].set_ylabel('Actual')\n",
    "        \n",
    "        # ROC Curve\n",
    "        from sklearn.metrics import roc_curve\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "        auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        \n",
    "        axes[1].plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.3f})')\n",
    "        axes[1].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "        axes[1].set_xlabel('False Positive Rate')\n",
    "        axes[1].set_ylabel('True Positive Rate')\n",
    "        axes[1].set_title('ROC Curve')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "        \n",
    "        # Distribution of Probabilities\n",
    "        axes[2].hist(y_pred_proba[y_true == 0], bins=30, alpha=0.7, label='Class 0', color='red')\n",
    "        axes[2].hist(y_pred_proba[y_true == 1], bins=30, alpha=0.7, label='Class 1', color='blue')\n",
    "        axes[2].set_xlabel('Predicted Probability')\n",
    "        axes[2].set_ylabel('Frequency')\n",
    "        axes[2].set_title('Distribution of Predicted Probabilities')\n",
    "        axes[2].legend()\n",
    "        axes[2].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_feature_importance(self, top_n=20):\n",
    "        \"\"\"\n",
    "        Visualize feature importance\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model has not been trained yet!\")\n",
    "        \n",
    "        # Get feature importance\n",
    "        feature_importance = self.model.feature_importances_\n",
    "        \n",
    "        if self.feature_names:\n",
    "            feature_names = self.feature_names\n",
    "        else:\n",
    "            feature_names = [f'Feature_{i}' for i in range(len(feature_importance))]\n",
    "        \n",
    "        # Create DataFrame for plotting\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': feature_importance\n",
    "        }).sort_values('importance', ascending=False).head(top_n)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(data=importance_df, x='importance', y='feature')\n",
    "        plt.title(f'Top {top_n} Feature Importances - TabNet')\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.grid(True, axis='x')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return importance_df\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"\n",
    "        Save the model\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model has not been trained yet!\")\n",
    "        \n",
    "        self.model.save_model(filepath)\n",
    "        print(f\"Model saved at: {filepath}\")\n",
    "    \n",
    "    def load_model(self, filepath):\n",
    "        \"\"\"\n",
    "        Load a saved model\n",
    "        \"\"\"\n",
    "        self.model = TabNetClassifier(device_name=self.device)\n",
    "        self.model.load_model(filepath)\n",
    "        self.is_fitted = True\n",
    "        print(f\"Model loaded from: {filepath}\")\n",
    "    \n",
    "    def get_model_summary(self):\n",
    "        \"\"\"\n",
    "        Return model and hardware summary\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            print(\"Model not yet trained\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n=== MODEL SUMMARY ===\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        print(f\"TabNet Parameters:\")\n",
    "        for key, value in self.tabnet_params.items():\n",
    "            if key != 'device_name':\n",
    "                print(f\"  - {key}: {value}\")\n",
    "        \n",
    "        if hasattr(self.model, 'network'):\n",
    "            total_params = sum(p.numel() for p in self.model.network.parameters())\n",
    "            trainable_params = sum(p.numel() for p in self.model.network.parameters() if p.requires_grad)\n",
    "            print(f\"Total parameters: {total_params:,}\")\n",
    "            print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        if self.device.startswith('cuda'):\n",
    "            self.get_gpu_memory_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU-optimized usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize classifier with GPU\n",
    "    classifier = TabNetBinaryClassifier(\n",
    "        n_d=64,\n",
    "        n_a=64, \n",
    "        n_steps=7,\n",
    "        gamma=1.5,\n",
    "        lambda_sparse=1e-3,\n",
    "        device_name='auto'  # Automatically detect GPU\n",
    "    )\n",
    "    \n",
    "    # Show GPU info\n",
    "    classifier.get_gpu_memory_info()\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train, X_test, y_train, y_test = classifier.prepare_data(X_subset, y_subset, target_col='y')\n",
    "    \n",
    "    # Train model (batch_size optimized for GPU)\n",
    "    model = classifier.train(\n",
    "        max_epochs=100, \n",
    "        patience=20, \n",
    "        batch_size=2048,  # Larger batch size for GPU\n",
    "        virtual_batch_size=256,\n",
    "        num_workers=4  # Parallel data loading\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bee904",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Evaluate performance\n",
    "    results = classifier.evaluate()\n",
    "    \n",
    "    # Show model summary\n",
    "    classifier.get_model_summary()\n",
    "    \n",
    "    # Show feature importance\n",
    "    importance_df = classifier.plot_feature_importance(top_n=15)\n",
    "    \n",
    "    # Save model\n",
    "    classifier.save_model('tabnet_binary_classifier_gpu.zip')\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    classifier.clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67605ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2267f7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcd4c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3b9b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14428b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "class TabNetBinaryClassifierOptuna:\n",
    "    \"\"\"\n",
    "    Class for training a TabNet binary classifier with GPU support and Optuna hyperparameter optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_d=32, \n",
    "                 n_a=32, \n",
    "                 n_steps=5, \n",
    "                 gamma=1.3,\n",
    "                 n_independent=2,\n",
    "                 n_shared=2,\n",
    "                 lambda_sparse=1e-3,\n",
    "                 optimizer_fn=torch.optim.Adam,\n",
    "                 optimizer_params=dict(lr=1e-2),\n",
    "                 mask_type='entmax',\n",
    "                 scheduler_params=dict(step_size=50, gamma=0.9),\n",
    "                 scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                 epsilon=1e-15,\n",
    "                 device_name='auto'):\n",
    "        \"\"\"\n",
    "        Initialize the TabNet classifier\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_d : int\n",
    "            Dimension of learned representations\n",
    "        n_a : int \n",
    "            Dimension of attention\n",
    "        n_steps : int\n",
    "            Number of steps in feature selection\n",
    "        gamma : float\n",
    "            Coefficient for aggregated attention\n",
    "        lambda_sparse : float\n",
    "            Regularization coefficient for sparsity\n",
    "        device_name : str\n",
    "            'auto', 'cuda', 'cpu' or specific device ('cuda:0')\n",
    "        \"\"\"\n",
    "        \n",
    "        # Device configuration\n",
    "        self.device = self._setup_device(device_name)\n",
    "        print(f\"Device used: {self.device}\")\n",
    "        \n",
    "        self.tabnet_params = {\n",
    "            'n_d': n_d,\n",
    "            'n_a': n_a, \n",
    "            'n_steps': n_steps,\n",
    "            'gamma': gamma,\n",
    "            'n_independent': n_independent,\n",
    "            'n_shared': n_shared,\n",
    "            'lambda_sparse': lambda_sparse,\n",
    "            'optimizer_fn': optimizer_fn,\n",
    "            'optimizer_params': optimizer_params,\n",
    "            'mask_type': mask_type,\n",
    "            'scheduler_params': scheduler_params,\n",
    "            'scheduler_fn': scheduler_fn,\n",
    "            'epsilon': epsilon,\n",
    "            'device_name': self.device\n",
    "        }\n",
    "        \n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_names = None\n",
    "        self.is_fitted = False\n",
    "        self.best_params = None\n",
    "        self.study = None\n",
    "        \n",
    "    def _setup_device(self, device_name):\n",
    "        \"\"\"\n",
    "        Configure the computing device (CPU/GPU)\n",
    "        \"\"\"\n",
    "        if device_name == 'auto':\n",
    "            if torch.cuda.is_available():\n",
    "                device = 'cuda'\n",
    "                print(f\"GPU available: {torch.cuda.get_device_name()}\")\n",
    "                print(f\"GPU memory available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "            else:\n",
    "                device = 'cpu'\n",
    "                print(\"GPU not available, using CPU\")\n",
    "        else:\n",
    "            device = device_name\n",
    "            if device.startswith('cuda') and not torch.cuda.is_available():\n",
    "                print(\"WARNING: GPU requested but not available, using CPU\")\n",
    "                device = 'cpu'\n",
    "        \n",
    "        return device\n",
    "    \n",
    "    def get_gpu_memory_info(self):\n",
    "        \"\"\"\n",
    "        Returns GPU memory information\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available() and self.device.startswith('cuda'):\n",
    "            device_idx = 0 if self.device == 'cuda' else int(self.device.split(':')[1])\n",
    "            allocated = torch.cuda.memory_allocated(device_idx) / 1e9\n",
    "            reserved = torch.cuda.memory_reserved(device_idx) / 1e9\n",
    "            total = torch.cuda.get_device_properties(device_idx).total_memory / 1e9\n",
    "            \n",
    "            print(f\"GPU Memory:\")\n",
    "            print(f\"  - Allocated: {allocated:.2f} GB\")\n",
    "            print(f\"  - Reserved: {reserved:.2f} GB\") \n",
    "            print(f\"  - Total: {total:.2f} GB\")\n",
    "            print(f\"  - Free: {total - reserved:.2f} GB\")\n",
    "            \n",
    "            return {\n",
    "                'allocated': allocated,\n",
    "                'reserved': reserved,\n",
    "                'total': total,\n",
    "                'free': total - reserved\n",
    "            }\n",
    "        else:\n",
    "            print(\"GPU memory not available\")\n",
    "            return None\n",
    "    \n",
    "    def clear_gpu_memory(self):\n",
    "        \"\"\"\n",
    "        Clear GPU memory\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"GPU cache cleared\")\n",
    "    \n",
    "    def prepare_data(self, X, y, target_col='y', test_size=0.2, random_state=42, scale_features=True):\n",
    "        \"\"\"\n",
    "        Prepare data for training\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pandas.DataFrame\n",
    "            DataFrame with data\n",
    "        target_col : str\n",
    "            Name of target column\n",
    "        test_size : float\n",
    "            Proportion of test set\n",
    "        random_state : int\n",
    "            Seed for reproducibility\n",
    "        scale_features : bool\n",
    "            Whether to apply scaling to features\n",
    "        \"\"\"\n",
    "        \n",
    "        # Separate features and target\n",
    "        X = X\n",
    "        y = y\n",
    "        \n",
    "        # Save feature names\n",
    "        self.feature_names = X.columns.tolist()\n",
    "        \n",
    "        # Convert to float32 to optimize GPU memory\n",
    "        X = X.astype(np.float32)\n",
    "        \n",
    "        # Split X and y into train (64%), validation (16%), and test (20%) sets\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            test_size=0.2,\n",
    "            stratify=y,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp,\n",
    "            y_temp,\n",
    "            test_size=0.2,  # 0.2 * 0.8 = 0.16 of the original data\n",
    "            stratify=y_temp,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Reset indices for convenience\n",
    "        X_train = X_train.reset_index(drop=True)\n",
    "        X_val = X_val.reset_index(drop=True)\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "        y_train = y_train.reset_index(drop=True)\n",
    "        y_val = y_val.reset_index(drop=True)\n",
    "        y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "        # Numeric columns will be scaled by StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        \n",
    "\n",
    "        column_trans = ColumnTransformer(\n",
    "            [ ('scaler',scaler, FEATURES),\n",
    "            ], remainder='passthrough', n_jobs=-1)\n",
    "\n",
    "        train_X_transformed = column_trans.fit_transform(X_train, y_train)\n",
    "        val_X_transformed = column_trans.transform(X_val )\n",
    "        test_X_transformed = column_trans.transform(X_test)\n",
    "\n",
    "        self.X_train = train_X_transformed\n",
    "        self.X_val = val_X_transformed\n",
    "        self.X_test = test_X_transformed\n",
    "\n",
    "\n",
    "        \n",
    "        # Convert to float32 for GPU\n",
    "        self.X_train = X_train.values.astype(np.float32)\n",
    "        self.y_train = y_train.values.astype(np.int64)\n",
    "\n",
    "        self.X_test = X_test.values.astype(np.float32)\n",
    "        self.y_test = y_test.values.astype(np.int64)\n",
    "\n",
    "        self.X_val = X_val.values.astype(np.float32)\n",
    "        self.y_val = y_val.values.astype(np.int64)\n",
    "\n",
    "        print(\"Data prepared:\")\n",
    "        print(f\"  - Training set: {self.X_train.shape}\")\n",
    "        print(f\"  - Test set: {self.X_test.shape}\")\n",
    "        print(f\"  - Validation set: {self.X_val.shape}\")\n",
    "\n",
    "        \n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "\n",
    "    def optimize_hyperparameters(self, \n",
    "                                n_trials=50,\n",
    "                                study_name=None,\n",
    "                                metric='auc',\n",
    "                                direction='maximize',\n",
    "                                pruning=True,\n",
    "                                n_jobs=-1,\n",
    "                                timeout=None,\n",
    "                                max_epochs_optuna=50,\n",
    "                                patience_optuna=10):\n",
    "        \"\"\"\n",
    "        Optimize hyperparameters using Optuna\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_trials : int\n",
    "            Number of optimization trials\n",
    "        study_name : str\n",
    "            Name for the study (optional)\n",
    "        metric : str\n",
    "            Metric to optimize ('auc' or 'accuracy')\n",
    "        direction : str\n",
    "            'maximize' or 'minimize'\n",
    "        pruning : bool\n",
    "            Whether to use pruning for early trial termination\n",
    "        n_jobs : int\n",
    "            Number of parallel jobs (1 for sequential)\n",
    "        timeout : int\n",
    "            Time limit in seconds (None for no limit)\n",
    "        max_epochs_optuna : int\n",
    "            Max epochs for each trial (reduced for faster optimization)\n",
    "        patience_optuna : int\n",
    "            Patience for each trial (reduced for faster optimization)\n",
    "        \"\"\"\n",
    "        \n",
    "        if not hasattr(self, 'X_train'):\n",
    "            raise ValueError(\"You must first prepare data with prepare_data()\")\n",
    "        \n",
    "        print(\"\\n=== STARTING HYPERPARAMETER OPTIMIZATION ===\")\n",
    "        print(f\"Trials: {n_trials}\")\n",
    "        print(f\"Metric: {metric}\")\n",
    "        print(f\"Direction: {direction}\")\n",
    "        print(f\"Max epochs per trial: {max_epochs_optuna}\")\n",
    "        \n",
    "        def objective(trial):\n",
    "            \"\"\"\n",
    "            Objective function for Optuna optimization\n",
    "            \"\"\"\n",
    "            \n",
    "            # Suggest hyperparameters\n",
    "            params = {\n",
    "                'n_d': trial.suggest_int('n_d', 8, 128),\n",
    "                'n_a': trial.suggest_int('n_a', 8, 128),\n",
    "                'n_steps': trial.suggest_int('n_steps', 3, 10),\n",
    "                'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n",
    "                'n_independent': trial.suggest_int('n_independent', 1, 5),\n",
    "                'n_shared': trial.suggest_int('n_shared', 1, 5),\n",
    "                'lambda_sparse': trial.suggest_float('lambda_sparse', 1e-6, 1e-1, log=True),\n",
    "                'optimizer_fn': torch.optim.Adam,\n",
    "                'optimizer_params': {\n",
    "                    'lr': trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "                },\n",
    "                'mask_type': 'entmax',\n",
    "                'scheduler_params': {\n",
    "                    'step_size': trial.suggest_int('step_size', 10, 100),\n",
    "                    'gamma': trial.suggest_float('scheduler_gamma', 0.8, 0.99)\n",
    "                },\n",
    "                'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
    "                'epsilon': 1e-15,\n",
    "                'device_name': self.device\n",
    "            }\n",
    "            \n",
    "            # Training parameters\n",
    "            batch_size = trial.suggest_categorical('batch_size', [256, 512, 1024, 2048])\n",
    "            virtual_batch_size = trial.suggest_categorical('virtual_batch_size', [64, 128, 256])\n",
    "            \n",
    "            # Create temporary model\n",
    "            temp_model = TabNetClassifier(**params)\n",
    "            \n",
    "            try:\n",
    "                # Clear GPU memory before each trial\n",
    "                if self.device.startswith('cuda'):\n",
    "                    self.clear_gpu_memory()\n",
    "                \n",
    "                # Train model\n",
    "                temp_model.fit(\n",
    "                    X_train=self.X_train,\n",
    "                    y_train=self.y_train.reshape(-1),\n",
    "                    eval_set=[(self.X_val, self.y_val.reshape(-1))],\n",
    "                    eval_name=['val'],\n",
    "                    eval_metric=['accuracy', 'auc'],\n",
    "                    max_epochs=max_epochs_optuna,\n",
    "                    patience=patience_optuna,\n",
    "                    batch_size=batch_size,\n",
    "                    virtual_batch_size=virtual_batch_size,\n",
    "                    num_workers=0,\n",
    "                    drop_last=False\n",
    "                )\n",
    "                \n",
    "                # Make predictions on validation set\n",
    "                y_pred_proba = temp_model.predict_proba(self.X_val)\n",
    "                y_pred = temp_model.predict(self.X_val)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                if metric == 'auc':\n",
    "                    score = roc_auc_score(self.y_val, y_pred_proba[:, 1])\n",
    "                elif metric == 'accuracy':\n",
    "                    score = accuracy_score(self.y_val, y_pred)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported metric: {metric}\")\n",
    "                \n",
    "                # Report intermediate values for pruning\n",
    "                trial.report(score, step=max_epochs_optuna)\n",
    "                \n",
    "                # Handle pruning\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.exceptions.TrialPruned()\n",
    "                \n",
    "                return score\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Trial failed: {str(e)}\")\n",
    "                # Return worst possible score for failed trials\n",
    "                return 0.0 if direction == 'maximize' else float('inf')\n",
    "            \n",
    "            finally:\n",
    "                # Clean up memory\n",
    "                del temp_model\n",
    "                if self.device.startswith('cuda'):\n",
    "                    self.clear_gpu_memory()\n",
    "        \n",
    "        # Create study\n",
    "        sampler = TPESampler(seed=42)\n",
    "        pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=10) if pruning else None\n",
    "        \n",
    "        study_name = study_name or f\"tabnet_optimization_{metric}\"\n",
    "        self.study = optuna.create_study(\n",
    "            direction=direction,\n",
    "            sampler=sampler,\n",
    "            pruner=pruner,\n",
    "            study_name=study_name\n",
    "        )\n",
    "        \n",
    "        # Run optimization\n",
    "        print(\"\\nRunning optimization...\")\n",
    "        self.study.optimize(\n",
    "            objective, \n",
    "            n_trials=n_trials,\n",
    "            n_jobs=n_jobs,\n",
    "            timeout=timeout,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        # Store best parameters\n",
    "        self.best_params = self.study.best_params.copy()\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\n=== OPTIMIZATION COMPLETED ===\")\n",
    "        print(f\"Best {metric}: {self.study.best_value:.4f}\")\n",
    "        print(f\"Best parameters:\")\n",
    "        for key, value in self.best_params.items():\n",
    "            print(f\"  - {key}: {value}\")\n",
    "        \n",
    "        print(f\"\\nOptimization statistics:\")\n",
    "        print(f\"  - Total trials: {len(self.study.trials)}\")\n",
    "        print(f\"  - Completed trials: {len([t for t in self.study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\")\n",
    "        print(f\"  - Pruned trials: {len([t for t in self.study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "        print(f\"  - Failed trials: {len([t for t in self.study.trials if t.state == optuna.trial.TrialState.FAIL])}\")\n",
    "        \n",
    "        return self.study\n",
    "    \n",
    "    def train_with_best_params(self, \n",
    "                              max_epochs=200, \n",
    "                              patience=15,\n",
    "                              num_workers=0,\n",
    "                              drop_last=False):\n",
    "        \"\"\"\n",
    "        Train model with best parameters found by Optuna\n",
    "        \"\"\"\n",
    "        if self.best_params is None:\n",
    "            raise ValueError(\"You must first run optimize_hyperparameters()\")\n",
    "        \n",
    "        print(f\"\\n=== TRAINING WITH BEST PARAMETERS ===\")\n",
    "        \n",
    "        # Extract training parameters\n",
    "        batch_size = self.best_params.pop('batch_size', 1024)\n",
    "        virtual_batch_size = self.best_params.pop('virtual_batch_size', 128)\n",
    "        lr = self.best_params.pop('lr', 1e-2)\n",
    "        step_size = self.best_params.pop('step_size', 50)\n",
    "        scheduler_gamma = self.best_params.pop('scheduler_gamma', 0.9)\n",
    "        \n",
    "        # Update tabnet_params with best parameters\n",
    "        self.tabnet_params.update(self.best_params)\n",
    "        self.tabnet_params['optimizer_params'] = {'lr': lr}\n",
    "        self.tabnet_params['scheduler_params'] = {'step_size': step_size, 'gamma': scheduler_gamma}\n",
    "        \n",
    "        # Train with original method using best parameters\n",
    "        return self.train(\n",
    "            max_epochs=max_epochs,\n",
    "            patience=patience,\n",
    "            batch_size=batch_size,\n",
    "            virtual_batch_size=virtual_batch_size,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=drop_last\n",
    "        )\n",
    "    \n",
    "    def plot_optimization_history(self):\n",
    "        \"\"\"\n",
    "        Plot optimization history\n",
    "        \"\"\"\n",
    "        if self.study is None:\n",
    "            raise ValueError(\"No optimization study found. Run optimize_hyperparameters() first.\")\n",
    "        \n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            import seaborn as sns\n",
    "            \n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "            \n",
    "            # Optimization history\n",
    "            trials = self.study.trials\n",
    "            values = [t.value for t in trials if t.value is not None]\n",
    "            \n",
    "            axes[0, 0].plot(values)\n",
    "            axes[0, 0].set_title('Optimization History')\n",
    "            axes[0, 0].set_xlabel('Trial')\n",
    "            axes[0, 0].set_ylabel('Objective Value')\n",
    "            axes[0, 0].grid(True)\n",
    "            \n",
    "            # Parameter importance\n",
    "            try:\n",
    "                importance = optuna.importance.get_param_importances(self.study)\n",
    "                params = list(importance.keys())[:10]  # Top 10\n",
    "                importances = [importance[p] for p in params]\n",
    "                \n",
    "                axes[0, 1].barh(params, importances)\n",
    "                axes[0, 1].set_title('Parameter Importance (Top 10)')\n",
    "                axes[0, 1].set_xlabel('Importance')\n",
    "            except:\n",
    "                axes[0, 1].text(0.5, 0.5, 'Parameter importance\\nnot available', \n",
    "                               ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "            \n",
    "            # Parallel coordinate plot data preparation\n",
    "            if len(trials) > 1:\n",
    "                # Select top parameters to show\n",
    "                param_names = ['n_d', 'n_a', 'n_steps', 'lr', 'batch_size']\n",
    "                trial_data = []\n",
    "                for trial in trials:\n",
    "                    if trial.value is not None:\n",
    "                        row = [trial.value]\n",
    "                        for param in param_names:\n",
    "                            if param in trial.params:\n",
    "                                row.append(trial.params[param])\n",
    "                            else:\n",
    "                                row.append(None)\n",
    "                        trial_data.append(row)\n",
    "                \n",
    "                if trial_data:\n",
    "                    import pandas as pd\n",
    "                    df = pd.DataFrame(trial_data, columns=['objective'] + param_names)\n",
    "                    df = df.dropna()\n",
    "                    \n",
    "                    if len(df) > 0:\n",
    "                        # Correlation heatmap\n",
    "                        corr = df.corr()\n",
    "                        sns.heatmap(corr, annot=True, cmap='coolwarm', center=0, ax=axes[1, 0])\n",
    "                        axes[1, 0].set_title('Parameter Correlation')\n",
    "                    else:\n",
    "                        axes[1, 0].text(0.5, 0.5, 'Insufficient data\\nfor correlation', \n",
    "                                       ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "            \n",
    "            # Best trial info\n",
    "            best_trial = self.study.best_trial\n",
    "            axes[1, 1].text(0.1, 0.9, f'Best Trial: #{best_trial.number}', fontsize=12, fontweight='bold', \n",
    "                           transform=axes[1, 1].transAxes)\n",
    "            axes[1, 1].text(0.1, 0.8, f'Best Value: {best_trial.value:.4f}', fontsize=11, \n",
    "                           transform=axes[1, 1].transAxes)\n",
    "            \n",
    "            # Show top parameters\n",
    "            y_pos = 0.7\n",
    "            axes[1, 1].text(0.1, y_pos, 'Best Parameters:', fontsize=11, fontweight='bold',\n",
    "                           transform=axes[1, 1].transAxes)\n",
    "            y_pos -= 0.08\n",
    "            \n",
    "            for key, value in list(best_trial.params.items())[:8]:  # Show top 8 params\n",
    "                axes[1, 1].text(0.1, y_pos, f'{key}: {value}', fontsize=9,\n",
    "                               transform=axes[1, 1].transAxes)\n",
    "                y_pos -= 0.06\n",
    "            \n",
    "            axes[1, 1].set_xlim(0, 1)\n",
    "            axes[1, 1].set_ylim(0, 1)\n",
    "            axes[1, 1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"Matplotlib/Seaborn not available for plotting\")\n",
    "    \n",
    "    def get_optimization_summary(self):\n",
    "        \"\"\"\n",
    "        Get summary of optimization results\n",
    "        \"\"\"\n",
    "        if self.study is None:\n",
    "            raise ValueError(\"No optimization study found. Run optimize_hyperparameters() first.\")\n",
    "        \n",
    "        summary = {\n",
    "            'best_value': self.study.best_value,\n",
    "            'best_params': self.study.best_params,\n",
    "            'n_trials': len(self.study.trials),\n",
    "            'completed_trials': len([t for t in self.study.trials if t.state == optuna.trial.TrialState.COMPLETE]),\n",
    "            'pruned_trials': len([t for t in self.study.trials if t.state == optuna.trial.TrialState.PRUNED]),\n",
    "            'failed_trials': len([t for t in self.study.trials if t.state == optuna.trial.TrialState.FAIL]),\n",
    "            'study_name': self.study.study_name\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "    # ==================== METODI ORIGINALI INVARIATI ====================\n",
    "    \n",
    "    def train(self, \n",
    "              max_epochs=200, \n",
    "              patience=15, \n",
    "              batch_size=1024,\n",
    "              virtual_batch_size=128,\n",
    "              num_workers=0,\n",
    "              drop_last=False):\n",
    "        \"\"\"\n",
    "        Train the TabNet model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        max_epochs : int\n",
    "            Maximum number of epochs\n",
    "        patience : int\n",
    "            Patience for early stopping\n",
    "        batch_size : int\n",
    "            Batch size\n",
    "        virtual_batch_size : int\n",
    "            Virtual batch size\n",
    "        num_workers : int\n",
    "            Number of workers for DataLoader (0 for GPU)\n",
    "        \"\"\"\n",
    "        \n",
    "        if not hasattr(self, 'X_train'):\n",
    "            raise ValueError(\"You must first prepare data with prepare_data()\")\n",
    "        \n",
    "        # Adapt batch_size for GPU\n",
    "        if self.device.startswith('cuda'):\n",
    "            gpu_memory = self.get_gpu_memory_info()\n",
    "            if gpu_memory and gpu_memory['free'] < 2.0:  # Less than 2GB free\n",
    "                suggested_batch_size = min(batch_size, 512)\n",
    "                print(f\"Limited GPU memory, reducing batch_size to {suggested_batch_size}\")\n",
    "                batch_size = suggested_batch_size\n",
    "            \n",
    "            # Optimize num_workers for GPU\n",
    "            if num_workers == 0:\n",
    "                num_workers = min(4, torch.cuda.device_count() * 2)\n",
    "                \n",
    "        print(\"Training configuration:\")\n",
    "        print(f\"  - Device: {self.device}\")\n",
    "        print(f\"  - Batch size: {batch_size}\")\n",
    "        print(f\"  - Virtual batch size: {virtual_batch_size}\")\n",
    "        print(f\"  - Num workers: {num_workers}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = TabNetClassifier(**self.tabnet_params)\n",
    "        \n",
    "        # Check memory before training\n",
    "        if self.device.startswith('cuda'):\n",
    "            self.clear_gpu_memory()\n",
    "            print(\"GPU memory before training:\")\n",
    "            self.get_gpu_memory_info()\n",
    "        \n",
    "        # Training\n",
    "        print(\"\\nStarting TabNet training...\") \n",
    "        \n",
    "        try:\n",
    "            self.model.fit(\n",
    "                X_train=self.X_train,\n",
    "                y_train=self.y_train,\n",
    "                eval_set=[(self.X_val, self.y_val)],\n",
    "                eval_name=['test'],\n",
    "                eval_metric=['accuracy', 'auc'],\n",
    "                max_epochs=max_epochs,\n",
    "                patience=patience,\n",
    "                batch_size=batch_size,\n",
    "                virtual_batch_size=virtual_batch_size,\n",
    "                num_workers=num_workers,\n",
    "                drop_last=drop_last,\n",
    "            )\n",
    "            \n",
    "            self.is_fitted = True\n",
    "            print(\"Training completed!\")\n",
    "            \n",
    "            # Check memory after training\n",
    "            if self.device.startswith('cuda'):\n",
    "                print(\"\\nGPU memory after training:\")\n",
    "                self.get_gpu_memory_info()\n",
    "                \n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e).lower():\n",
    "                print(\"\\nERROR: Insufficient GPU memory!\")\n",
    "                self.clear_gpu_memory()\n",
    "            raise e\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, X=None):\n",
    "        \"\"\"\n",
    "        Make predictions\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model has not been trained yet!\")\n",
    "        \n",
    "        if X is None:\n",
    "            X = self.X_test\n",
    "            \n",
    "        # Convert to float32 for consistency\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values.astype(np.float32)\n",
    "        elif not isinstance(X, np.ndarray):\n",
    "            X = np.array(X, dtype=np.float32)\n",
    "        else:\n",
    "            X = X.astype(np.float32)\n",
    "            \n",
    "        predictions = self.model.predict(X)\n",
    "        return predictions\n",
    "    \n",
    "    def predict_proba(self, X=None):\n",
    "        \"\"\"\n",
    "        Return prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model has not been trained yet!\")\n",
    "        \n",
    "        if X is None:\n",
    "            X = self.X_test\n",
    "            \n",
    "        # Convert to float32 for consistency\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values.astype(np.float32)\n",
    "        elif not isinstance(X, np.ndarray):\n",
    "            X = np.array(X, dtype=np.float32)\n",
    "        else:\n",
    "            X = X.astype(np.float32)\n",
    "            \n",
    "        probabilities = self.model.predict_proba(X)\n",
    "        return probabilities\n",
    "    \n",
    "    def evaluate(self, X=None, y=None, plot_results=True):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model has not been trained yet!\")\n",
    "        \n",
    "        if X is None:\n",
    "            X = self.X_test\n",
    "            y = self.y_test\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = self.predict(X)\n",
    "        y_pred_proba = self.predict_proba(X)\n",
    "        \n",
    "        # Metrics\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        auc_score = roc_auc_score(y, y_pred_proba[:, 1])\n",
    "        \n",
    "        print(f\"\\n=== EVALUATION RESULTS ===\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"AUC Score: {auc_score:.4f}\")\n",
    "        print(f\"\\nClassification Report:\")\n",
    "        print(classification_report(y, y_pred))\n",
    "        \n",
    "        if plot_results:\n",
    "            self.plot_results(y, y_pred, y_pred_proba[:, 1])\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'auc_score': auc_score,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_pred_proba\n",
    "        }\n",
    "    \n",
    "    def plot_results(self, y_true, y_pred, y_pred_proba):\n",
    "        \"\"\"\n",
    "        Visualize results\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "        axes[0].set_title('Confusion Matrix')\n",
    "        axes[0].set_xlabel('Predicted')\n",
    "        axes[0].set_ylabel('Actual')\n",
    "        \n",
    "        # ROC Curve\n",
    "        from sklearn.metrics import roc_curve\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "        auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        \n",
    "        axes[1].plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.3f})')\n",
    "        axes[1].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "        axes[1].set_xlabel('False Positive Rate')\n",
    "        axes[1].set_ylabel('True Positive Rate')\n",
    "        axes[1].set_title('ROC Curve')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "        \n",
    "        # Distribution of Probabilities\n",
    "        axes[2].hist(y_pred_proba[y_true == 0], bins=30, alpha=0.7, label='Class 0', color='red')\n",
    "        axes[2].hist(y_pred_proba[y_true == 1], bins=30, alpha=0.7, label='Class 1', color='blue')\n",
    "        axes[2].set_xlabel('Predicted Probability')\n",
    "        axes[2].set_ylabel('Frequency')\n",
    "        axes[2].set_title('Distribution of Predicted Probabilities')\n",
    "        axes[2].legend()\n",
    "        axes[2].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_feature_importance(self, top_n=20):\n",
    "        \"\"\"\n",
    "        Visualize feature importance\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model has not been trained yet!\")\n",
    "        \n",
    "        # Get feature importance\n",
    "        feature_importance = self.model.feature_importances_\n",
    "        \n",
    "        if self.feature_names:\n",
    "            feature_names = self.feature_names\n",
    "        else:\n",
    "            feature_names = [f'Feature_{i}' for i in range(len(feature_importance))]\n",
    "        \n",
    "        # Create DataFrame for plotting\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': feature_importance\n",
    "        }).sort_values('importance', ascending=False).head(top_n)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(data=importance_df, x='importance', y='feature')\n",
    "        plt.title(f'Top {top_n} Feature Importances - TabNet')\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.grid(True, axis='x')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return importance_df\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"\n",
    "        Save the model\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model has not been trained yet!\")\n",
    "        \n",
    "        self.model.save_model(filepath)\n",
    "        print(f\"Model saved at: {filepath}\")\n",
    "    \n",
    "    def load_model(self, filepath):\n",
    "        \"\"\"\n",
    "        Load a saved model\n",
    "        \"\"\"\n",
    "        self.model = TabNetClassifier(device_name=self.device)\n",
    "        self.model.load_model(filepath)\n",
    "        self.is_fitted = True\n",
    "        print(f\"Model loaded from: {filepath}\")\n",
    "    \n",
    "    def get_model_summary(self):\n",
    "        \"\"\"\n",
    "        Return model and hardware summary\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            print(\"Model not yet trained\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n=== MODEL SUMMARY ===\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        print(f\"TabNet Parameters:\")\n",
    "        for key, value in self.tabnet_params.items():\n",
    "            if key != 'device_name':\n",
    "                print(f\"  - {key}: {value}\")\n",
    "        \n",
    "        if self.best_params:\n",
    "            print(f\"\\nOptimized Parameters:\")\n",
    "            for key, value in self.best_params.items():\n",
    "                print(f\"  - {key}: {value}\")\n",
    "        \n",
    "        if hasattr(self.model, 'network'):\n",
    "            total_params = sum(p.numel() for p in self.model.network.parameters())\n",
    "            trainable_params = sum(p.numel() for p in self.model.network.parameters() if p.requires_grad)\n",
    "            print(f\"Total parameters: {total_params:,}\")\n",
    "            print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        if self.device.startswith('cuda'):\n",
    "            self.get_gpu_memory_info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa2dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==================== ESEMPIO DI UTILIZZO ====================\n",
    "\n",
    "\n",
    "#Esempio di come usare la classe con ottimizzazione Optuna:\n",
    "\n",
    "# 1. Inizializza il classificatore\n",
    "classifier = TabNetBinaryClassifierOptuna(device_name='auto')\n",
    "\n",
    "# 2. Prepara i dati\n",
    "X_train, X_test, y_train, y_test = classifier.prepare_data(X_subset, y_subset, target_col='y')\n",
    "\n",
    "# 3. Ottimizza gli iperparametri\n",
    "study = classifier.optimize_hyperparameters(\n",
    "    n_trials=30,           # Numero di prove\n",
    "    metric='auc',          # Metrica da ottimizzare\n",
    "    max_epochs_optuna=10,  # Epoche ridotte per l'ottimizzazione\n",
    "    patience_optuna=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77af255",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Addestra con i migliori parametri\n",
    "model = classifier.train_with_best_params(\n",
    "    max_epochs=200,        # Epoche complete per il training finale\n",
    "    patience=15\n",
    ")\n",
    "\n",
    "# 5. Valuta il modello\n",
    "results = classifier.evaluate()\n",
    "\n",
    "# 6. Visualizza i risultati dell'ottimizzazione\n",
    "classifier.plot_optimization_history()\n",
    "\n",
    "# 7. Mostra il riassunto\n",
    "summary = classifier.get_optimization_summary()\n",
    "print(summary)\n",
    "\n",
    "# 8. Feature importance\n",
    "classifier.plot_feature_importance()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
